---
layout: single
title: "[트러블슈팅] AWS-transcribe stt chunk에 null 값이 들어옴"
toc: true
toc_sticky: true
categories: parrotalk
published: true
---

<details>
<summary>이전 상황 :</summary>
<div markdown="1">

STT와 TTS 기능이 들어간, 실시간 전화 통신과 채팅 시스템이 동시에 가능한 애플리케이션을 구현하고자 함
    
사용자는 상대방의 말을 텍스트로 보거나 들을 수 있고, 사용자가 텍스트를 쳤을 때 상대방에게 AI 보이스로 전달하여 전화하는 느낌이 드는 것을 목표로 한다.

기능 구현 방법으로는 **WebRTC** 방법과 **WebSocket을 활용한 Twilio API**를 사용하는 방법 중 고민했다.

팀 프로젝트 내에서는 WebRTC 방법을 채택하였다. 이유는 다음과 같다. (Twilio API는 개인플젝 진행예정)

1. twilio api의 경우 유료 서비스이다. (20$..)
2. 한국에 특성화되어 있지 않아 지원이 미비하고 한국 전화번호 구매 마다 25$가 발생한다..
3. 음질 테스트 결과 WebRTC가 압도적으로 우세했다.

링크를 참고하여 WebRTC 틀을 완성하였고 Node.js 환경에서 Express를 기반으로 한 웹 서버를 구축하였다. 음성 통화 통신 테스트 후 정상적으로 작동하는 것을 확인하였고 이후 AWS transcribe API 연결을 시도하였다.

[줌 클론코딩 – 노마드 코더 Nomad Coders](https://nomadcoders.co/noom)

</div>
</details>
    

## 문제 상황: stt chunk에 빈 값이 들어옴

<img width="400" alt="image" src="https://github.com/user-attachments/assets/2ee0deff-943e-48c7-8fd2-758f7f277c64">

클라이언트에서 받은 오디오 데이터를 **Audio Stream**에 추가하고 수신되는 Stream을 16KB 청크로 나누어 AWS Transcribe API에 전송한다. 

Transcribe 측에서는 Stream 속 event를 확인하고 번역을 진행한다.

**하지만, TranscriptEvent가 수신되는 것은 확인했으나 번역된 결과값(Results)에 아무 값이 들어오지 않는 것을 확인하였다.**

## 문제 원인 : 오디오 계산 문제

이전 코드

```jsx
convertFloat32ToInt16(buffer){
        return buffer.map(value => Math.max(-1, Math.min(1, value)) * 0x7FFF);
    }
```

`convertFloat32ToInt16` **반환 형식 확인**

`convertFloat32ToInt16` 함수가 현재 `buffer.map(...)`을 반환하고 있지만, `map`은 `Float32Array`를 반환한다. `Int16Array` 형식으로 명확히 반환되도록 수정이 필요하다.

변경 코드

```jsx
convertFloat32ToInt16(buffer) {
        const int16Buffer = new Int16Array(buffer.length);
        for (let i = 0; i < buffer.length; i++) {
            int16Buffer[i] = Math.max(-1, Math.min(1, buffer[i])) * 0x7FFF;
        }
        return int16Buffer;
    }
```

- 이렇게 하면 `Int16Array` 형식이 명확히 보장된다.

## 문제 해결

<img width="408" alt="%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-10-29_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_4 30 55" src="https://github.com/user-attachments/assets/a7d1fa19-3523-44a9-9f65-e8999deb9c06">
<img width="346" alt="image 1" src="https://github.com/user-attachments/assets/8570d221-1253-4dc4-b0a1-d4bc9e644d17">


**Text로 반환하는 것까지 성공**

하지만 “안녕하세요”를 연발했으나 사진과 같이 

“아”

“음”

“무”

어쩌다 한 번 “안녕하세요.” 가 출력되는데 정확도가 낮다

**심지어 “그런 경우가 없더라고요.” 라는 말이 출력됨 (내가 한말아님)**

- 없는 말을 지어내는 경우는 심각한 상황이라 판단

말을 하지 않아도 반환 값이 나오는 것으로 보아

→ 음성 데이터가 큰 대역폭을 담당해서 그런가 주위 소리도 들어가는 거 같음

## 결론 (현재 상황)

Speach To Text를 구현하긴 했으나 다음과 같은 문제점이 있다.

1. 정확도 낮음
2. 이상한 말 지어냄
3. 주위 소리가 들어감

⇒ 성능 향상이 필요하다.

[Austin-Choi/Zoom-WebRTC/PULL#1](https://github.com/Austin-Choi/Zoom-WebRTC/pull/1)
